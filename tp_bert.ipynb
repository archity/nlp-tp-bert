{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "tp_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e8d41145e8ec4fdb934eba3d27083d92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_c7ecc4abed094facb8aea17fc4e13da7",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_53afbbfdb147490fb776959ffac50242",
       "IPY_MODEL_f369027da2204bdf91054c24e6a7a7a9",
       "IPY_MODEL_c0fd3bd226bb4219b1c993c330c21fcf"
      ]
     }
    },
    "c7ecc4abed094facb8aea17fc4e13da7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "53afbbfdb147490fb776959ffac50242": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_0a368f5ab25845d09d01924ec3619ae1",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_04e3fb4dc932458897d69e573134fdc4"
     }
    },
    "f369027da2204bdf91054c24e6a7a7a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_e59f9bd4ea8a44019477b8ec0f611212",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 231508,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 231508,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f7a8fa6f5bca499b910dc2a3daf41567"
     }
    },
    "c0fd3bd226bb4219b1c993c330c21fcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_7dcea35bc315476f83af13f410966a04",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 226k/226k [00:00&lt;00:00, 359kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_4765c3fa657a450180182270f651aa35"
     }
    },
    "0a368f5ab25845d09d01924ec3619ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "04e3fb4dc932458897d69e573134fdc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e59f9bd4ea8a44019477b8ec0f611212": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f7a8fa6f5bca499b910dc2a3daf41567": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "7dcea35bc315476f83af13f410966a04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "4765c3fa657a450180182270f651aa35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "70fc8912fb004f4692cafe7c095bb8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_abe49bbfaf0d4d378498a488919c7a7f",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_f19887c9b777484c8050dcc57784b58d",
       "IPY_MODEL_c1f4ed8f067a4083abdd56f208c4e124",
       "IPY_MODEL_45589fdee7684378a154611b6c3b8a46"
      ]
     }
    },
    "abe49bbfaf0d4d378498a488919c7a7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f19887c9b777484c8050dcc57784b58d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d67482757dd54e12a90b85c486bd0ebe",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e1be31c761ed44f9b959cdd99042d31f"
     }
    },
    "c1f4ed8f067a4083abdd56f208c4e124": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_6f167408cf9341cdaa65bf4075a64cae",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 28,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 28,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e7e25c8392934fdf876f8f18929ccd8e"
     }
    },
    "45589fdee7684378a154611b6c3b8a46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_07ba28bd8f6f495d8f9cec81e5ad9888",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 28.0/28.0 [00:00&lt;00:00, 466B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_90f33529e7954cc6b27a4a54bfc2f7f2"
     }
    },
    "d67482757dd54e12a90b85c486bd0ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e1be31c761ed44f9b959cdd99042d31f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6f167408cf9341cdaa65bf4075a64cae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e7e25c8392934fdf876f8f18929ccd8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "07ba28bd8f6f495d8f9cec81e5ad9888": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "90f33529e7954cc6b27a4a54bfc2f7f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "7dec5718498f4a5fb342bfea3e017bb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5f63eafdc30940fa834d765c5b5b5d38",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_6d86283ad9f24bf1aa28b24ed2b71371",
       "IPY_MODEL_ac5ef3afb41e4a3782dd0a2fdc312d84",
       "IPY_MODEL_508083f2a5e14bd59d0104284fa29809"
      ]
     }
    },
    "5f63eafdc30940fa834d765c5b5b5d38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6d86283ad9f24bf1aa28b24ed2b71371": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_b369c4b3e7a0452d889eb4a3fa4a7c4e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_9a6c039af3a84a0f9e2f966dafd1853d"
     }
    },
    "ac5ef3afb41e4a3782dd0a2fdc312d84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_b4ebb917816a4a6d8847cae4652f33a9",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 466062,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 466062,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_95f2f871b3274ad6858bcbae6f4b185e"
     }
    },
    "508083f2a5e14bd59d0104284fa29809": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_f7608438dfe04333a1204ba6d1922aed",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 455k/455k [00:00&lt;00:00, 591kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c35ac90380444aedaacf588628af315c"
     }
    },
    "b369c4b3e7a0452d889eb4a3fa4a7c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "9a6c039af3a84a0f9e2f966dafd1853d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b4ebb917816a4a6d8847cae4652f33a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "95f2f871b3274ad6858bcbae6f4b185e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f7608438dfe04333a1204ba6d1922aed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c35ac90380444aedaacf588628af315c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a17e842c2e904608a3d4317ee6a09306": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5a327c2e13e04bba825c19acaf0a5c3b",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_ff4860d3721d493ca92e4db7b92aaf56",
       "IPY_MODEL_8dc19deb811c4330b91573bedf17b9a0",
       "IPY_MODEL_a4d08957dccf454099bcc766daa09a4c"
      ]
     }
    },
    "5a327c2e13e04bba825c19acaf0a5c3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ff4860d3721d493ca92e4db7b92aaf56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_1b6242915b594fdfbfdc92c625ac734b",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e69ef3612dcb43308a89b23c3b4aaebd"
     }
    },
    "8dc19deb811c4330b91573bedf17b9a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_79d7487fd54a4f16ada87623d3297ef2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 483,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 483,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_abfbe72d8e5b49ce97e5494248b062b3"
     }
    },
    "a4d08957dccf454099bcc766daa09a4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a9c63185f3ad4af19659cfb142e7dd00",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 483/483 [00:00&lt;00:00, 8.69kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_a0124091955b4c809a7bc2d7e8c773af"
     }
    },
    "1b6242915b594fdfbfdc92c625ac734b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e69ef3612dcb43308a89b23c3b4aaebd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "79d7487fd54a4f16ada87623d3297ef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "abfbe72d8e5b49ce97e5494248b062b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a9c63185f3ad4af19659cfb142e7dd00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "a0124091955b4c809a7bc2d7e8c773af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2541a13a1b744d48891a3cf169629fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_f8ef958de6d445ca9b5cc63990d1012b",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_24c44dd56ea74d8ab0f7976c7660d56a",
       "IPY_MODEL_b11e1038459d4749985f9eb665fdf735",
       "IPY_MODEL_86842c7acf4c4eb69a8f84257cfbde99"
      ]
     }
    },
    "f8ef958de6d445ca9b5cc63990d1012b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "24c44dd56ea74d8ab0f7976c7660d56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_5ce51a783a384c389b38d95230a7aabb",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_11d555f0397d44e1acc70d6700b9e72d"
     }
    },
    "b11e1038459d4749985f9eb665fdf735": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_df59d648a3b24a79b09de3dd761780f3",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 267967963,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 267967963,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_9158a768458b4ddda3a03eb68eb6faa9"
     }
    },
    "86842c7acf4c4eb69a8f84257cfbde99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_28ebf50996de42d7b18b6d9b0dda0aae",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 256M/256M [00:08&lt;00:00, 42.5MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_aab4c5bd5a9741c6a91252bd8ff7a487"
     }
    },
    "5ce51a783a384c389b38d95230a7aabb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "11d555f0397d44e1acc70d6700b9e72d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "df59d648a3b24a79b09de3dd761780f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "9158a768458b4ddda3a03eb68eb6faa9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "28ebf50996de42d7b18b6d9b0dda0aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "aab4c5bd5a9741c6a91252bd8ff7a487": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BERT Practical\n",
    "\n",
    "Practical work on BERT for the course Natural Language Processing in M2 MoSIG\n",
    "\n",
    "> Author: Archit YADAV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Iaxs5T3cfgPF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. IMPORT MODULES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "CCsTMRfzfgPK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hdlQuifgDMZ",
    "outputId": "76d415fc-5da7-41bf-f1aa-3b5271e69f87"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.4 MB 4.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 42.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 41.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001B[K     |████████████████████████████████| 895 kB 68.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001B[K     |████████████████████████████████| 61 kB 478 kB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4e-cM3FPUE-V"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Managing arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Will work on CPU.\n"
     ]
    }
   ],
   "source": [
    "# load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"GPU is available.\")\n",
    "  device = torch.cuda.current_device()\n",
    "else:\n",
    "  print(\"Will work on CPU.\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kk0dCwOmfgPM",
    "outputId": "aecce07e-b413-4e4e-8590-3938525a83f2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. DATA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "fPaN19rhfgPN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Downloading of Data"
   ],
   "metadata": {
    "id": "_sr62iV-hYRA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset size: \n",
      "3885 posts in total\n",
      "\t 2332 training posts\n",
      "\t\t 593 comp.windows.x\n",
      "\t\t 594 sci.med\n",
      "\t\t 599 soc.religion.christian\n",
      "\t\t 546 talk.politics.guns\n",
      "\t 1553 testing posts\n",
      "\t\t 395 comp.windows.x\n",
      "\t\t 396 sci.med\n",
      "\t\t 398 soc.religion.christian\n",
      "\t\t 364 talk.politics.guns\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    " 'comp.windows.x',\n",
    " 'sci.med',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    "]\n",
    "\n",
    "# Download data if not already present in data_home\n",
    "trainset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, data_home='./scikit_learn_data')\n",
    "testset = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, data_home='./scikit_learn_data')\n",
    "\n",
    "# Define input data and labels for training and testing\n",
    "x_train = trainset.data\n",
    "y_train = trainset.target\n",
    "x_test = testset.data\n",
    "y_test = testset.target\n",
    "\n",
    "# SOLUTION (yes, we are cool)\n",
    "print('Dataset size: \\n{} posts in total'.format(len(x_train) + len(x_test)))\n",
    "print('\\t {} training posts'.format(len(x_train)))\n",
    "\n",
    "for i in range(len(categories)):\n",
    "  num = sum(y_train == i)\n",
    "  print(\"\\t\\t {} {}\".format(num, categories[i]))\n",
    "\n",
    "print('\\t {} testing posts'.format(len(x_test)))\n",
    "for i in range(len(categories)):\n",
    "  num = sum(y_test == i)\n",
    "  print(\"\\t\\t {} {}\".format(num, categories[i]))\n",
    "\n",
    "\n",
    "\n",
    "# print('\\n')\n",
    "# print('EXAMPLE: \\n')\n",
    "# print(x_train[0])\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaiRgy0yfgPN",
    "outputId": "2a964210-92d1-42b0-f6bd-0442d8cb76ca"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Cleaning of Data"
   ],
   "metadata": {
    "id": "MRgRZaothcE4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove lines starting with certain keywords \n",
    "def clean_post(post: str, remove_start: tuple):\n",
    "    clean_lines = []\n",
    "    for line in post.splitlines():\n",
    "            if not line.startswith(remove_start):\n",
    "                clean_lines.append(line)\n",
    "    return '\\n'.join(clean_lines)\n",
    "    \n",
    "\n",
    "# SOLUTION (yes, again, we are cool)\n",
    "remove_start = (\n",
    "  'From:',\n",
    "  'Subject:',\n",
    "  'Reply-To:',\n",
    "  'In-Reply-To:',\n",
    "  'Nntp-Posting-Host:',\n",
    "  'Organization:',\n",
    "  'X-Mailer:',\n",
    "  'In article <',\n",
    "  'Lines:',\n",
    "  'NNTP-Posting-Host:',\n",
    "  'Summary:',\n",
    "  'Article-I.D.:'\n",
    ")\n",
    "x_train = [clean_post(p, remove_start) for p in x_train]\n",
    "x_test = [clean_post(p, remove_start) for p in x_test]\n"
   ],
   "metadata": {
    "id": "Ma4tJ6NKhTSR"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. TOKENISATION"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "L2mmpMT6fgPO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d41145e8ec4fdb934eba3d27083d92",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc8912fb004f4692cafe7c095bb8fa",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dec5718498f4a5fb342bfea3e017bb6",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17e842c2e904608a3d4317ee6a09306",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'input_ids': [101, 1996, 13758, 1006, 10900, 1015, 1024, 2570, 1007, 1996, 13758, 2758, 1010, 1036, 1036, 2054, 2003, 3606, 1029, 1005, 1005, 1998, 4332, 2000, 19021, 2243, 1999, 1996, 17005, 1997, 2010, 12746, 1012, 2129, 2715, 2129, 15236, 2129, 5622, 5677, 5844, 2129, 2715, 2129, 15236, 2129, 5622, 5677, 5844, 2027, 16883, 1996, 13758, 1010, 2108, 2137, 2987, 1005, 1056, 2113, 2008, 2010, 1036, 1036, 3160, 1005, 1005, 2715, 18386, 26881, 2001, 2356, 2077, 1010, 2011, 1037, 2715, 18386, 26881, 3923, 2063, 24686, 3761, 1006, 2805, 2025, 2700, 1007, 2040, 3047, 2000, 2444, 2048, 4595, 2086, 3283, 1012, 2066, 2116, 8801, 2002, 8725, 2625, 2055, 15084, 2084, 3463, 2625, 2055, 4515, 2084, 2965, 2625, 2055, 2505, 2084, 4363, 2010, 3105, 1006, 1998, 2010, 2132, 1007, 1012, 2057, 2453, 2655, 2032, 1037, 2978, 12077, 2295, 1036, 3813, 1005, 2052, 2022, 2785, 2121, 1006, 1998, 2053, 4797, 13125, 1010, 2040, 2292, 6343, 2175, 1010, 4191, 2012, 2010, 27327, 2791, 1007, 2002, 2134, 1005, 1056, 2066, 2010, 3105, 1025, 3383, 2002, 2053, 2936, 5113, 2005, 2488, 1006, 4496, 8615, 4788, 1010, 3272, 4953, 2010, 2132, 1007, 1012, 1998, 2043, 2122, 19863, 2100, 5181, 2007, 2037, 4641, 1011, 1045, 1011, 2663, 1010, 17448, 1011, 2017, 1011, 4558, 9530, 8630, 6824, 2015, 2716, 5743, 2037, 28441, 1010, 2010, 2034, 14982, 2001, 2000, 2377, 1996, 3142, 1024, 1036, 1036, 1045, 2424, 2498, 3308, 2007, 2032, 1010, 2156, 2000, 2009, 25035, 1012, 1005, 1005, 2021, 2043, 2027, 3855, 1036, 2332, 1005, 1998, 1036, 11604, 1005, 2010, 2540, 10619, 1012, 2065, 2002, 2730, 2037, 28441, 2002, 1005, 1040, 2707, 1037, 11421, 1998, 4558, 2010, 3105, 1006, 1998, 2010, 2132, 1007, 2065, 2002, 5552, 1996, 2332, 1997, 1996, 5181, 2002, 1005, 1040, 18138, 2125, 11604, 1998, 4558, 2010, 3105, 1006, 1998, 2010, 2132, 1007, 1998, 2043, 2010, 2564, 2409, 2032, 2000, 2031, 2498, 2000, 2079, 2007, 1996, 19556, 10223, 2102, 2016, 2134, 1005, 1056, 2425, 2032, 2505, 2002, 2910, 1005, 1056, 2525, 6618, 2041, 1012, 2061, 2002, 18975, 2098, 1012, 1036, 1036, 2025, 2026, 7360, 999, 2202, 2032, 2000, 2156, 5394, 2094, 999, 1005, 1005, 1006, 2040, 2074, 3047, 2000, 2022, 1999, 2237, 1012, 1012, 1012, 1012, 1007, 5394, 2094, 12315, 1996, 14571, 2021, 2347, 1005, 1056, 5191, 1998, 2741, 1996, 4629, 1011, 4416, 2094, 7966, 1006, 2040, 3402, 2134, 1005, 1056, 2031, 2172, 2000, 2360, 1010, 6057, 2129, 2111, 4558, 2009, 2104, 3778, 1012, 1012, 1012, 1012, 1007, 2067, 1999, 1996, 20426, 5372, 2000, 2010, 2548, 2110, 1012, 2010, 4632, 2003, 3139, 1011, 1011, 1011, 2065, 5394, 2094, 2038, 2053, 3291, 1010, 11604, 5121, 2180, 1005, 1056, 1012, 1996, 7966, 2064, 2022, 2332, 1997, 3649, 2088, 2002, 4122, 2004, 2146, 2004, 2009, 1005, 1055, 2025, 11604, 1005, 1055, 1012, 1036, 1036, 1045, 1005, 1049, 5599, 2032, 2175, 1010, 1005, 1005, 2002, 2056, 2007, 1037, 11245, 1012, 1006, 3504, 2066, 2002, 1005, 2222, 2197, 2023, 2028, 2041, 1012, 1012, 1012, 1012, 1007, 1996, 4306, 1005, 1055, 4668, 14909, 2032, 1012, 2027, 2428, 2359, 2032, 2757, 1012, 2027, 2134, 1005, 1056, 2215, 1996, 2332, 1997, 1996, 5181, 1010, 2027, 2359, 3347, 7875, 22083, 2612, 1006, 1998, 1010, 2004, 3312, 2271, 2636, 1010, 2027, 2288, 2032, 1007, 2821, 2092, 1010, 2002, 2245, 1010, 2027, 2035, 2298, 1996, 2168, 2000, 2033, 1012, 1998, 2057, 1005, 2222, 2131, 3347, 7875, 22083, 2279, 2051, 1012, 1998, 2065, 1045, 2064, 2131, 2068, 2000, 2360, 1036, 1036, 2057, 2031, 2053, 2332, 2021, 11604, 999, 1005, 1005, 2011, 4288, 1037, 28441, 1010, 3109, 1010, 1045, 1005, 2222, 3102, 2702, 1037, 2154, 1012, 1998, 2059, 14255, 13806, 2018, 2010, 4569, 1037, 2210, 8257, 2460, 2000, 1996, 2391, 13012, 2989, 8787, 1998, 2035, 2023, 2253, 2004, 2009, 2467, 2515, 2043, 2619, 4152, 3236, 1999, 1996, 19456, 1997, 2231, 1998, 2045, 1005, 1055, 1037, 4045, 7526, 1006, 2053, 4797, 1007, 2005, 1996, 3565, 16643, 20771, 11256, 1006, 29486, 2075, 2000, 2023, 2154, 1007, 2008, 2009, 2134, 1005, 1056, 2035, 2203, 2007, 1037, 8136, 1998, 1037, 3142, 3704, 2006, 3457, 1012, 2256, 13758, 2987, 1005, 1056, 2113, 2055, 2023, 2002, 2987, 1005, 1056, 6807, 2010, 2785, 5596, 4382, 1006, 2030, 3606, 2593, 1010, 2004, 2002, 14456, 1007, 1012, 1045, 3984, 2057, 4033, 1005, 1056, 4342, 2172, 1999, 2048, 4595, 2086, 1012, 1011, 1011, 1011, 5965, 13097, 3511, 13097, 3511, 1030, 20116, 2140, 1012, 5185, 1012, 4012, 1000, 3521, 2003, 2069, 2488, 2084, 2162, 2043, 2009, 1005, 1055, 2025, 3109, 2205, 1012, 2162, 2108, 3109, 3084, 3168, 1012, 1000, 1011, 5232, 11312, 1010, 1996, 2117, 2746, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'the', 'sophomore', '(', 'romans', '1', ':', '22', ')', 'the', 'sophomore', 'says', ',', '`', '`', 'what', 'is', 'truth', '?', \"'\", \"'\", 'and', 'turns', 'to', 'bas', '##k', 'in', 'the', 'admiration', 'of', 'his', 'peers', '.', 'how', 'modern', 'how', 'daring', 'how', 'li', '##ber', '##ating', 'how', 'modern', 'how', 'daring', 'how', 'li', '##ber', '##ating', 'they', 'chant', 'the', 'sophomore', ',', 'being', 'american', 'doesn', \"'\", 't', 'know', 'that', 'his', '`', '`', 'question', \"'\", \"'\", 'modern', 'skeptical', 'cynical', 'was', 'asked', 'before', ',', 'by', 'a', 'modern', 'skeptical', 'cynical', 'urban', '##e', 'cosmopolitan', 'politician', '(', 'appointed', 'not', 'elected', ')', 'who', 'happened', 'to', 'live', 'two', 'thousand', 'years', 'ago', '.', 'like', 'many', 'politicians', 'he', 'cared', 'less', 'about', 'ideals', 'than', 'results', 'less', 'about', 'ends', 'than', 'means', 'less', 'about', 'anything', 'than', 'keeping', 'his', 'job', '(', 'and', 'his', 'head', ')', '.', 'we', 'might', 'call', 'him', 'a', 'bit', 'brutal', 'though', '`', 'firm', \"'\", 'would', 'be', 'kind', '##er', '(', 'and', 'no', 'doubt', 'stalin', ',', 'who', 'let', 'nobody', 'go', ',', 'laughed', 'at', 'his', 'lax', '##ness', ')', 'he', 'didn', \"'\", 't', 'like', 'his', 'job', ';', 'perhaps', 'he', 'no', 'longer', 'hoped', 'for', 'better', '(', 'nor', 'feared', 'worse', ',', 'except', 'regarding', 'his', 'head', ')', '.', 'and', 'when', 'these', 'wil', '##y', 'jews', 'with', 'their', 'heads', '-', 'i', '-', 'win', ',', 'tails', '-', 'you', '-', 'lose', 'con', '##und', '##rum', '##s', 'brought', 'forth', 'their', 'madman', ',', 'his', 'first', 'impulse', 'was', 'to', 'play', 'the', 'roman', ':', '`', '`', 'i', 'find', 'nothing', 'wrong', 'with', 'him', ',', 'see', 'to', 'it', 'yourselves', '.', \"'\", \"'\", 'but', 'when', 'they', 'mentioned', '`', 'king', \"'\", 'and', '`', 'caesar', \"'\", 'his', 'heart', 'froze', '.', 'if', 'he', 'killed', 'their', 'madman', 'he', \"'\", 'd', 'start', 'a', 'riot', 'and', 'lose', 'his', 'job', '(', 'and', 'his', 'head', ')', 'if', 'he', 'saved', 'the', 'king', 'of', 'the', 'jews', 'he', \"'\", 'd', 'piss', 'off', 'caesar', 'and', 'lose', 'his', 'job', '(', 'and', 'his', 'head', ')', 'and', 'when', 'his', 'wife', 'told', 'him', 'to', 'have', 'nothing', 'to', 'do', 'with', 'the', 'righteous', 'lou', '##t', 'she', 'didn', \"'\", 't', 'tell', 'him', 'anything', 'he', 'hadn', \"'\", 't', 'already', 'figured', 'out', '.', 'so', 'he', 'punt', '##ed', '.', '`', '`', 'not', 'my', 'jurisdiction', '!', 'take', 'him', 'to', 'see', 'hero', '##d', '!', \"'\", \"'\", '(', 'who', 'just', 'happened', 'to', 'be', 'in', 'town', '.', '.', '.', '.', ')', 'hero', '##d', 'appreciated', 'the', 'courtesy', 'but', 'wasn', \"'\", 't', 'worried', 'and', 'sent', 'the', 'sharp', '-', 'tongue', '##d', 'fool', '(', 'who', 'suddenly', 'didn', \"'\", 't', 'have', 'much', 'to', 'say', ',', 'funny', 'how', 'people', 'lose', 'it', 'under', 'pressure', '.', '.', '.', '.', ')', 'back', 'in', 'the', 'attire', 'proper', 'to', 'his', 'royal', 'state', '.', 'his', 'ass', 'is', 'covered', '-', '-', '-', 'if', 'hero', '##d', 'has', 'no', 'problem', ',', 'caesar', 'certainly', 'won', \"'\", 't', '.', 'the', 'fool', 'can', 'be', 'king', 'of', 'whatever', 'world', 'he', 'wants', 'as', 'long', 'as', 'it', \"'\", 's', 'not', 'caesar', \"'\", 's', '.', '`', '`', 'i', \"'\", 'm', 'letting', 'him', 'go', ',', \"'\", \"'\", 'he', 'said', 'with', 'a', 'shout', '.', '(', 'looks', 'like', 'he', \"'\", 'll', 'last', 'this', 'one', 'out', '.', '.', '.', '.', ')', 'the', 'crowd', \"'\", 's', 'reaction', 'puzzled', 'him', '.', 'they', 'really', 'wanted', 'him', 'dead', '.', 'they', 'didn', \"'\", 't', 'want', 'the', 'king', 'of', 'the', 'jews', ',', 'they', 'wanted', 'bar', '##ab', '##bas', 'instead', '(', 'and', ',', 'as', 'joseph', '##us', 'records', ',', 'they', 'got', 'him', ')', 'oh', 'well', ',', 'he', 'thought', ',', 'they', 'all', 'look', 'the', 'same', 'to', 'me', '.', 'and', 'we', \"'\", 'll', 'get', 'bar', '##ab', '##bas', 'next', 'time', '.', 'and', 'if', 'i', 'can', 'get', 'them', 'to', 'say', '`', '`', 'we', 'have', 'no', 'king', 'but', 'caesar', '!', \"'\", \"'\", 'by', 'killing', 'a', 'madman', ',', 'hell', ',', 'i', \"'\", 'll', 'kill', 'ten', 'a', 'day', '.', 'and', 'then', 'pi', '##late', 'had', 'his', 'fun', 'a', 'little', 'joke', 'short', 'to', 'the', 'point', 'tri', '##ling', '##ual', 'and', 'all', 'this', 'went', 'as', 'it', 'always', 'does', 'when', 'someone', 'gets', 'caught', 'in', 'the', 'gears', 'of', 'government', 'and', 'there', \"'\", 's', 'a', 'scientific', 'explanation', '(', 'no', 'doubt', ')', 'for', 'the', 'super', '##sti', '##tious', 'rumors', '(', 'persist', '##ing', 'to', 'this', 'day', ')', 'that', 'it', 'didn', \"'\", 't', 'all', 'end', 'with', 'a', 'tomb', 'and', 'a', 'roman', 'squadron', 'on', 'guard', '.', 'our', 'sophomore', 'doesn', \"'\", 't', 'know', 'about', 'this', 'he', 'doesn', \"'\", 't', 'recognize', 'his', 'kind', '##red', 'spirit', '(', 'or', 'truth', 'either', ',', 'as', 'he', 'admits', ')', '.', 'i', 'guess', 'we', 'haven', \"'\", 't', 'learned', 'much', 'in', 'two', 'thousand', 'years', '.', '-', '-', '-', 'fred', 'gil', '##ham', 'gil', '##ham', '@', 'cs', '##l', '.', 'sri', '.', 'com', '\"', 'peace', 'is', 'only', 'better', 'than', 'war', 'when', 'it', \"'\", 's', 'not', 'hell', 'too', '.', 'war', 'being', 'hell', 'makes', 'sense', '.', '\"', '-', 'walker', 'percy', ',', 'the', 'second', 'coming', '[SEP]'] \n",
      "\n",
      "[CLS] the sophomore ( romans 1 : 22 ) the sophomore says, ` ` what is truth?'' and turns to bask in the admiration of his peers. how modern how daring how liberating how modern how daring how liberating they chant the sophomore, being american doesn't know that his ` ` question'' modern skeptical cynical was asked before, by a modern skeptical cynical urbane cosmopolitan politician ( appointed not elected ) who happened to live two thousand years ago. like many politicians he cared less about ideals than results less about ends than means less about anything than keeping his job ( and his head ). we might call him a bit brutal though ` firm'would be kinder ( and no doubt stalin, who let nobody go, laughed at his laxness ) he didn't like his job ; perhaps he no longer hoped for better ( nor feared worse, except regarding his head ). and when these wily jews with their heads - i - win, tails - you - lose conundrums brought forth their madman, his first impulse was to play the roman : ` ` i find nothing wrong with him, see to it yourselves.'' but when they mentioned ` king'and ` caesar'his heart froze. if he killed their madman he'd start a riot and lose his job ( and his head ) if he saved the king of the jews he'd piss off caesar and lose his job ( and his head ) and when his wife told him to have nothing to do with the righteous lout she didn't tell him anything he hadn't already figured out. so he punted. ` ` not my jurisdiction! take him to see herod!'' ( who just happened to be in town.... ) herod appreciated the courtesy but wasn't worried and sent the sharp - tongued fool ( who suddenly didn't have much to say, funny how people lose it under pressure.... ) back in the attire proper to his royal state. his ass is covered - - - if herod has no problem, caesar certainly won't. the fool can be king of whatever world he wants as long as it's not caesar's. ` ` i'm letting him go,'' he said with a shout. ( looks like he'll last this one out.... ) the crowd's reaction puzzled him. they really wanted him dead. they didn't want the king of the jews, they wanted barabbas instead ( and, as josephus records, they got him ) oh well, he thought, they all look the same to me. and we'll get barabbas next time. and if i can get them to say ` ` we have no king but caesar!'' by killing a madman, hell, i'll kill ten a day. and then pilate had his fun a little joke short to the point trilingual and all this went as it always does when someone gets caught in the gears of government and there's a scientific explanation ( no doubt ) for the superstitious rumors ( persisting to this day ) that it didn't all end with a tomb and a roman squadron on guard. our sophomore doesn't know about this he doesn't recognize his kindred spirit ( or truth either, as he admits ). i guess we haven't learned much in two thousand years. - - - fred gilham gilham @ csl. sri. com \" peace is only better than war when it's not hell too. war being hell makes sense. \" - walker percy, the second coming [SEP] \n",
      "\n",
      "---------------- \n",
      "\n",
      "{'input_ids': [101, 1028, 1045, 2001, 5327, 2008, 1011, 1011, 2174, 1996, 3663, 2001, 10395, 1011, 1011, 1996, 1028, 3200, 2052, 3961, 10109, 1010, 2061, 1996, 18079, 1005, 1056, 2071, 5271, 2009, 2000, 2393, 3477, 2005, 1996, 1028, 5606, 1997, 5190, 1997, 6363, 1997, 11727, 22667, 2383, 2000, 3336, 28032, 1028, 1047, 20409, 2100, 12849, 21898, 1004, 2010, 19311, 1997, 8351, 1012, 1028, 1999, 2070, 2148, 2137, 3032, 1010, 2044, 2576, 6151, 2229, 7895, 13510, 5419, 1010, 1996, 2155, 2052, 2131, 1037, 5060, 1997, 2331, 1998, 1037, 3021, 2005, 1996, 13148, 1997, 1996, 2303, 1012, 2017, 4593, 2228, 2008, 2052, 2022, 1037, 2204, 2801, 1012, 1996, 2976, 2231, 7531, 2023, 2895, 2114, 12849, 21898, 1998, 2010, 8771, 1010, 5129, 2068, 2005, 4868, 2420, 1010, 5117, 1999, 8317, 8309, 1010, 2109, 3082, 2510, 3941, 2114, 2149, 4480, 2006, 2149, 5800, 1025, 1998, 2085, 2008, 1996, 7328, 3236, 2543, 2096, 2027, 2020, 14107, 1999, 20116, 3806, 2044, 10591, 8198, 1999, 1996, 2311, 1025, 4487, 3736, 6767, 9333, 2035, 5368, 1012, 2502, 2567, 2003, 2025, 2467, 2157, 1012, 1008, 1008, 1008, 2703, 4388, 2358, 7140, 18142, 2102, 1008, 1008, 1008, 3996, 10133, 2966, 2415, 1008, 1008, 1008, 4274, 1024, 21877, 2015, 2509, 1030, 12731, 3490, 2595, 2546, 1012, 10507, 1012, 3996, 1012, 3968, 2226, 1008, 1008, 1008, 2035, 10740, 2024, 2026, 2219, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', '>', 'i', 'was', 'hoping', 'that', '-', '-', 'however', 'the', 'situation', 'was', 'resolved', '-', '-', 'the', '>', 'property', 'would', 'remain', 'intact', ',', 'so', 'the', 'gov', \"'\", 't', 'could', 'sell', 'it', 'to', 'help', 'pay', 'for', 'the', '>', 'hundreds', 'of', 'thousands', 'of', 'dollars', 'of', 'expenses', 'incurred', 'having', 'to', 'baby', '##sit', '>', 'k', '##raz', '##y', 'ko', '##resh', '&', 'his', 'flock', 'of', 'sheep', '.', '>', 'in', 'some', 'south', 'american', 'countries', ',', 'after', 'political', 'und', '##es', '##ira', '##bles', 'disappeared', ',', 'the', 'family', 'would', 'get', 'a', 'notice', 'of', 'death', 'and', 'a', 'bill', 'for', 'the', 'disposal', 'of', 'the', 'body', '.', 'you', 'apparently', 'think', 'that', 'would', 'be', 'a', 'good', 'idea', '.', 'the', 'federal', 'government', 'initiated', 'this', 'action', 'against', 'ko', '##resh', 'and', 'his', 'followers', ',', 'surrounded', 'them', 'for', '51', 'days', ',', 'engaged', 'in', 'psychological', 'warfare', ',', 'used', 'heavy', 'military', 'equipment', 'against', 'us', 'citizens', 'on', 'us', 'soil', ';', 'and', 'now', 'that', 'the', 'compound', 'caught', 'fire', 'while', 'they', 'were', 'pumping', 'in', 'cs', 'gas', 'after', 'knocking', 'holes', 'in', 'the', 'building', ';', 'di', '##sa', '##vo', '##ws', 'all', 'responsibility', '.', 'big', 'brother', 'is', 'not', 'always', 'right', '.', '*', '*', '*', 'paul', 'eric', 'st', '##ou', '##ffle', '##t', '*', '*', '*', 'columbia', 'presbyterian', 'medical', 'center', '*', '*', '*', 'internet', ':', 'pe', '##s', '##3', '@', 'cu', '##ni', '##x', '##f', '.', 'cc', '.', 'columbia', '.', 'ed', '##u', '*', '*', '*', 'all', 'opinions', 'are', 'my', 'own', '[SEP]'] \n",
      "\n",
      "[CLS] > i was hoping that - - however the situation was resolved - - the > property would remain intact, so the gov't could sell it to help pay for the > hundreds of thousands of dollars of expenses incurred having to babysit > krazy koresh & his flock of sheep. > in some south american countries, after political undesirables disappeared, the family would get a notice of death and a bill for the disposal of the body. you apparently think that would be a good idea. the federal government initiated this action against koresh and his followers, surrounded them for 51 days, engaged in psychological warfare, used heavy military equipment against us citizens on us soil ; and now that the compound caught fire while they were pumping in cs gas after knocking holes in the building ; disavows all responsibility. big brother is not always right. * * * paul eric stoufflet * * * columbia presbyterian medical center * * * internet : pes3 @ cunixf. cc. columbia. edu * * * all opinions are my own [SEP] \n",
      "\n",
      "---------------- \n",
      "\n",
      "{'input_ids': [101, 1999, 2831, 1012, 4331, 1012, 4409, 1010, 14855, 5620, 2102, 15136, 1009, 1030, 15091, 1012, 3968, 2226, 1006, 6498, 1037, 7977, 2386, 1007, 7009, 1024, 2092, 6498, 1045, 5993, 2007, 2017, 2000, 2070, 4847, 1012, 1012, 1012, 2625, 2115, 11379, 10697, 1012, 1996, 18079, 1005, 24098, 2102, 2467, 2442, 2663, 999, 2130, 2065, 2027, 3102, 2296, 2158, 2308, 1998, 2775, 1012, 1012, 1012, 1012, 2011, 2643, 2027, 2442, 2663, 2012, 2035, 5366, 1012, 1012, 1012, 1012, 1012, 1012, 2023, 6433, 2058, 1998, 2058, 1998, 2058, 1999, 2023, 2406, 1012, 11082, 2191, 21917, 1010, 2131, 1996, 22692, 2811, 2000, 3104, 2039, 2673, 1010, 2292, 1996, 4584, 2202, 1996, 3684, 2005, 2327, 2968, 28072, 4385, 1012, 1012, 1012, 4385, 1012, 1012, 1012, 1028, 1045, 2572, 5305, 2007, 24665, 7416, 2546, 2005, 1996, 2972, 2092, 2108, 1997, 2023, 3842, 1998, 1996, 1028, 4552, 1999, 4447, 2000, 4047, 1012, 1028, 1028, 2101, 1010, 1028, 6498, 1028, 1028, 2101, 22294, 2100, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'in', 'talk', '.', 'politics', '.', 'guns', ',', 'ja', '##gs', '##t', '##18', '+', '@', 'pitt', '.', 'ed', '##u', '(', 'josh', 'a', 'gross', '##man', ')', 'writes', ':', 'well', 'josh', 'i', 'agree', 'with', 'you', 'to', 'some', 'respect', '.', '.', '.', 'less', 'your', 'spelling', 'errors', '.', 'the', 'gov', \"'\", 'mn', '##t', 'always', 'must', 'win', '!', 'even', 'if', 'they', 'kill', 'every', 'man', 'women', 'and', 'child', '.', '.', '.', '.', 'by', 'god', 'they', 'must', 'win', 'at', 'all', 'costs', '.', '.', '.', '.', '.', '.', 'this', 'happens', 'over', 'and', 'over', 'and', 'over', 'in', 'this', 'country', '.', 'lets', 'make', 'excuses', ',', 'get', 'the', 'worthless', 'press', 'to', 'cover', 'up', 'everything', ',', 'let', 'the', 'officials', 'take', 'the', 'heat', 'for', 'top', 'management', 'stupidity', 'etc', '.', '.', '.', 'etc', '.', '.', '.', '>', 'i', 'am', 'sick', 'with', 'gr', '##ei', '##f', 'for', 'the', 'entire', 'well', 'being', 'of', 'this', 'nation', 'and', 'the', '>', 'constitution', 'in', 'claims', 'to', 'protect', '.', '>', '>', 'later', ',', '>', 'josh', '>', '>', 'later', 'mort', '##y', '[SEP]'] \n",
      "\n",
      "[CLS] in talk. politics. guns, jagst18 + @ pitt. edu ( josh a grossman ) writes : well josh i agree with you to some respect... less your spelling errors. the gov'mnt always must win! even if they kill every man women and child.... by god they must win at all costs...... this happens over and over and over in this country. lets make excuses, get the worthless press to cover up everything, let the officials take the heat for top management stupidity etc... etc... > i am sick with greif for the entire well being of this nation and the > constitution in claims to protect. > > later, > josh > > later morty [SEP] \n",
      "\n",
      "---------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', padding=True, truncation=True)\n",
    "\n",
    "# Let's check out how the tokenizer works\n",
    "for n in range(3):\n",
    "    # Tokenize forum post\n",
    "    tokenizer_out = tokenizer(x_train[n])\n",
    "    # Convert numerical tokens to alphabetical tokens\n",
    "    encoded_tok = tokenizer.convert_ids_to_tokens(tokenizer_out.input_ids)\n",
    "    # Decode tokens back to string\n",
    "    decoded = tokenizer.decode(tokenizer_out.input_ids)\n",
    "    print(tokenizer_out)\n",
    "    print(encoded_tok, '\\n')\n",
    "    print(decoded, '\\n')\n",
    "    print('---------------- \\n')\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546,
     "referenced_widgets": [
      "e8d41145e8ec4fdb934eba3d27083d92",
      "c7ecc4abed094facb8aea17fc4e13da7",
      "53afbbfdb147490fb776959ffac50242",
      "f369027da2204bdf91054c24e6a7a7a9",
      "c0fd3bd226bb4219b1c993c330c21fcf",
      "0a368f5ab25845d09d01924ec3619ae1",
      "04e3fb4dc932458897d69e573134fdc4",
      "e59f9bd4ea8a44019477b8ec0f611212",
      "f7a8fa6f5bca499b910dc2a3daf41567",
      "7dcea35bc315476f83af13f410966a04",
      "4765c3fa657a450180182270f651aa35",
      "70fc8912fb004f4692cafe7c095bb8fa",
      "abe49bbfaf0d4d378498a488919c7a7f",
      "f19887c9b777484c8050dcc57784b58d",
      "c1f4ed8f067a4083abdd56f208c4e124",
      "45589fdee7684378a154611b6c3b8a46",
      "d67482757dd54e12a90b85c486bd0ebe",
      "e1be31c761ed44f9b959cdd99042d31f",
      "6f167408cf9341cdaa65bf4075a64cae",
      "e7e25c8392934fdf876f8f18929ccd8e",
      "07ba28bd8f6f495d8f9cec81e5ad9888",
      "90f33529e7954cc6b27a4a54bfc2f7f2",
      "7dec5718498f4a5fb342bfea3e017bb6",
      "5f63eafdc30940fa834d765c5b5b5d38",
      "6d86283ad9f24bf1aa28b24ed2b71371",
      "ac5ef3afb41e4a3782dd0a2fdc312d84",
      "508083f2a5e14bd59d0104284fa29809",
      "b369c4b3e7a0452d889eb4a3fa4a7c4e",
      "9a6c039af3a84a0f9e2f966dafd1853d",
      "b4ebb917816a4a6d8847cae4652f33a9",
      "95f2f871b3274ad6858bcbae6f4b185e",
      "f7608438dfe04333a1204ba6d1922aed",
      "c35ac90380444aedaacf588628af315c",
      "a17e842c2e904608a3d4317ee6a09306",
      "5a327c2e13e04bba825c19acaf0a5c3b",
      "ff4860d3721d493ca92e4db7b92aaf56",
      "8dc19deb811c4330b91573bedf17b9a0",
      "a4d08957dccf454099bcc766daa09a4c",
      "1b6242915b594fdfbfdc92c625ac734b",
      "e69ef3612dcb43308a89b23c3b4aaebd",
      "79d7487fd54a4f16ada87623d3297ef2",
      "abfbe72d8e5b49ce97e5494248b062b3",
      "a9c63185f3ad4af19659cfb142e7dd00",
      "a0124091955b4c809a7bc2d7e8c773af"
     ]
    },
    "id": "QaJLo-4wfgPP",
    "outputId": "837b912c-d238-4d5d-d8b3-1f1a2a7ff9eb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "class PostsDataset(Dataset):\n",
    "    def __init__(self, posts, labels, tokenizer, max_len):\n",
    "        # Variables that are set when the class is instantiated\n",
    "        self.posts = posts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.posts)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        # Select the post and its category\n",
    "        post = str(self.posts[item])\n",
    "        label = self.labels[item]\n",
    "        # Tokenize the post\n",
    "        tokenizer_out = self.tokenizer(\n",
    "            post,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "            )\n",
    "        # Return a dictionary with the output of the tokenizer and the label\n",
    "        return  {\n",
    "            'input_ids': tokenizer_out['input_ids'].flatten(),\n",
    "            'attention_mask': tokenizer_out['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "# Instantiate two PostsDatasets\n",
    "train_dataset = PostsDataset(x_train, y_train, tokenizer, MAX_LEN)\n",
    "test_dataset = PostsDataset(x_test, y_test, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "id": "Q-TwXpvoksBc"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "eY2w_htDfgPQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2541a13a1b744d48891a3cf169629fd3",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "distilbert = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    " \n",
    "first_post = train_dataset[0]\n",
    "\n",
    "hidden_state = distilbert(\n",
    "    input_ids=first_post['input_ids'].unsqueeze(0),\n",
    "    attention_mask=first_post['attention_mask'].unsqueeze(0)\n",
    "    )\n",
    "\n",
    "print(hidden_state[0].shape)\n",
    "print(distilbert.config)\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590,
     "referenced_widgets": [
      "2541a13a1b744d48891a3cf169629fd3",
      "f8ef958de6d445ca9b5cc63990d1012b",
      "24c44dd56ea74d8ab0f7976c7660d56a",
      "b11e1038459d4749985f9eb665fdf735",
      "86842c7acf4c4eb69a8f84257cfbde99",
      "5ce51a783a384c389b38d95230a7aabb",
      "11d555f0397d44e1acc70d6700b9e72d",
      "df59d648a3b24a79b09de3dd761780f3",
      "9158a768458b4ddda3a03eb68eb6faa9",
      "28ebf50996de42d7b18b6d9b0dda0aae",
      "aab4c5bd5a9741c6a91252bd8ff7a487"
     ]
    },
    "id": "xnhWAdLNfgPR",
    "outputId": "750963fc-a5d6-4981-e1ef-6ee55e0ab20a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DistilBertPreTrainedModel, DistilBertConfig\n",
    "\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "class DistilBertForPostClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels, freeze_encoder=False):\n",
    "        # Instantiate the parent class DistilBertPreTrainedModel\n",
    "        super().__init__(config)\n",
    "        # Instantiate num. of classes\n",
    "        self.num_labels = num_labels\n",
    "        # Instantiate and load a pretrained DistilBERT model as encoder\n",
    "        self.encoder = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        # Freeze the encoder parameters if required (Q1)\n",
    "        if freeze_encoder:\n",
    "          for param in self.encoder.parameters():\n",
    "              param.requires_grad = False\n",
    "        # The classifier: a feed-forward layer attached to the encoder's head\n",
    "        self.classifier = torch.nn.Linear(\n",
    "            in_features=config.dim, out_features=self.num_labels, bias=True)\n",
    "        # Instantiate a dropout function for the classifier's input\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "    ):\n",
    "        # Encode a batch of sequences with DistilBERT\n",
    "        encoder_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "        # Extract the hidden representations from the encoder output\n",
    "        hidden_state = encoder_output[0]  # (bs, seq_len, dim)\n",
    "        # Only select the encoding corresponding to the first token\n",
    "        # of each sequence in the batch (Q2)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        # Apply dropout\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        # Feed into the classifier\n",
    "        logits = self.classifier(pooled_output)  # (bs, dim)\n",
    "\n",
    "        outputs = (logits,) + encoder_output[1:]\n",
    "        \n",
    "        if labels is not None: # (Q3)\n",
    "          # Instantiate loss function\n",
    "          # SOLUTION :\n",
    "          loss_fct = torch.nn.CrossEntropyLoss()\n",
    "          # Calculate loss\n",
    "          # SOLUTION :\n",
    "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "          # Aggregate outputs\n",
    "          outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = DistilBertForPostClassification(\n",
    "    config=distilbert.config, num_labels=len(categories), freeze_encoder = True\n",
    "    )\n",
    "\n",
    "# Print info about model's parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('Model total params: ', total_params)\n",
    "print('Model trainable params: ', trainable_params)\n",
    "print('\\n', model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCuSAhqRnFvr",
    "outputId": "d8340511-d778-4187-883a-e39e9d266988"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model total params:  66365956\n",
      "Model trainable params:  3076\n",
      "\n",
      " DistilBertForPostClassification(\n",
      "  (encoder): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. TRAINING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "b1sqdw_-fgPR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 2332\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1168\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='752' max='1168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 752/1168 1:44:02 < 57:42, 0.12 it/s, Epoch 2.57/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.409900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.244300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.200600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.086700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    logging_dir='./logs',\n",
    "    logging_first_step=True,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=4,              \n",
    "    per_device_train_batch_size=8,  \n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01        \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_results = trainer.train()\n",
    "\n",
    "test_results = trainer.predict(test_dataset=test_dataset)\n",
    "\n",
    "print('Predictions: \\n', test_results.predictions)\n",
    "print('\\nAccuracy: ', test_results.metrics['eval_accuracy'])\n",
    "print('Precision: ', test_results.metrics['eval_precision'])\n",
    "print('Recall: ', test_results.metrics['eval_recall'])\n",
    "print('F1: ', test_results.metrics['eval_f1'])\n",
    "print(categories)\n",
    "\n",
    "MODEL_PATH = './my_model'\n",
    "trainer.save_model(MODEL_PATH)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "yzNYv5-nfgPS",
    "outputId": "ef4b9bcf-fa80-4fd0-fc66-bb9a9967c297"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. PREDICTIONS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "YdqRrsJufgPS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = DistilBertForPostClassification.from_pretrained(\n",
    "    './my_model', config=distilbert.config, num_labels=len(categories)).to(device)\n",
    "for sentence in ['Lung cancer is a deadly disease.', 'God is love', 'How can you install Microsoft Office extensions?', 'Gun killings increase every year.']:\n",
    "  encoding = tokenizer.encode_plus(sentence)\n",
    "  encoding['input_ids'] = torch.tensor([encoding.input_ids]).to(device)\n",
    "  encoding['attention_mask'] = torch.tensor(encoding.attention_mask).to(device)\n",
    "  out = model(**encoding)\n",
    "  categories_probability = torch.nn.functional.softmax(out[0], dim=1).flatten()\n",
    "  print(sentence)\n",
    "  print('\\tProbabilities assigned by the model : ')\n",
    "  for n,c in enumerate(categories):\n",
    "    print('\\t\\t{} : {}'.format(c, categories_probability[n]))\n",
    "  print('\\n\\t--> Prediction :', categories[categories_probability.argmax()])\n",
    "  print('------------------------------------------------\\n')\n",
    "  "
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "6fNKdHPnfgPS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. IMPROVE THE MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "BwRhEXFqfgPT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# # SOLUTION 1 (trivial): increase training epochs\n",
    "# # SOLUTION 2: finetune encoder parameters too\n",
    "\n",
    "# model_unfreezed = DistilBertForPostClassification(config, freeze_decoder = False)\n",
    "# trainer_unfreezed = Trainer(\n",
    "#     model=model_unfreezed,                         \n",
    "#     args=training_args,                  \n",
    "#     train_dataset=train_dataset,         \n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n",
    "# trainer_unfreezed.train()\n",
    "# trainer_unfreezed.predict(test_dataset=test_dataset)\n",
    "\n",
    "# # SOLUTION 3: let's see what students can do !\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rH2Mxl0CfgPT"
   }
  }
 ]
}